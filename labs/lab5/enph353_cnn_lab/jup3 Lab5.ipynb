{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 images from folder:\n",
      "/home/fizzer/enph353_git/beep-boop/labs/lab5/enph353_cnn_lab/resized_numbers\n",
      "Loaded 26 images from folder:\n",
      "/home/fizzer/enph353_git/beep-boop/labs/lab5/enph353_cnn_lab/resized_letters\n",
      "Total examples: 36\n",
      "Training examples: 29\n",
      "Test examples: 7\n",
      "X shape:(36, 140, 100, 4)\n",
      "Y shape:(36, 36)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2 \n",
    "\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as ipywidgets\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "from keras import backend\n",
    "from keras.utils import *\n",
    "\n",
    "\n",
    "# Constants\n",
    "LETTER_PATH = '/home/fizzer/enph353_git/beep-boop/labs/lab5/enph353_cnn_lab/resized_letters'\n",
    "NUMBER_PATH = '/home/fizzer/enph353_git/beep-boop/labs/lab5/enph353_cnn_lab/resized_numbers'\n",
    "H = 298\n",
    "W = 600\n",
    "NUMBER_OF_LABELS = 36                # Number of different labels, 10 + 26 = 36\n",
    "CONFIDENCE_THRESHOLD = 0.05          # How accurate the training model is\n",
    "VALIDATION_SPLIT = 0.2               # Portion of dataset to be used in validation\n",
    "\n",
    "\n",
    "def files_in_folder(folder_path):\n",
    "  '''\n",
    "  Returns a list of strings where each entry is a file in the folder_path.\n",
    "  \n",
    "  Parameters\n",
    "  ----------\n",
    "  \n",
    "  folder_path : str\n",
    "     A string to folder for which the file listing is returned.\n",
    "     \n",
    "  '''\n",
    "  files_A = !ls \"{folder_path}\"\n",
    "  # The files when listed from Google Drive have a particular format. They are\n",
    "  # grouped in sets of 4 and have spaces and tabs as delimiters.\n",
    "  \n",
    "  # Split the string listing sets of 4 files by tab and space and remove any \n",
    "  # empty splits.\n",
    "  files_B = [list(filter(None, re.split('\\t|\\s', files))) for files in files_A]\n",
    "  \n",
    "  # Concatenate all splits into a single sorted list\n",
    "  files_C = []\n",
    "  for element in files_B:\n",
    "    files_C = files_C + element\n",
    "  files_C.sort()\n",
    "  \n",
    "  return files_C\n",
    "\n",
    "\n",
    "def convert_to_one_hot(Y,C):\n",
    "    '''\n",
    "    Returns an array of one hot encoding for dataset Y, with size C.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    Y : array\n",
    "        An array of the dataset.\n",
    "        \n",
    "    C : int\n",
    "        The size of the array.\n",
    "        \n",
    "    '''\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y\n",
    "\n",
    "\n",
    "def displayImage(index):\n",
    "    '''\n",
    "    Displays image of a specified index.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    index : int\n",
    "        The index of image to be displayed.\n",
    "        \n",
    "    '''\n",
    "    plt.imshow(X_charset[index])\n",
    "    caption = (\"y = \" + str(Y_charset[index]))\n",
    "    plt.text(0.5, 0.5, caption, \n",
    "            color = 'orange', fontsize = 20,\n",
    "            horizontalalignment = 'left', verticalalignment = 'top')\n",
    "    \n",
    "# Reinitialize model parameters.\n",
    "def reset_weights(model):\n",
    "    session = backend.get_session()\n",
    "    for layer in model.layers:\n",
    "        \n",
    "        # Look for the layer with attribute = 'kernel_initializer' and run session\n",
    "        if hasattr(layer, 'kernel_initializer'):\n",
    "            layer.kernel.initializer.run(session=session)\n",
    "\n",
    "# Specifying paths to folder\n",
    "letter_folder = LETTER_PATH\n",
    "number_folder = NUMBER_PATH\n",
    "\n",
    "# Generating a list of files in the specified folder\n",
    "letters = files_in_folder(letter_folder)\n",
    "numbers = files_in_folder(number_folder)\n",
    "\n",
    "# Open the images for numbers and label each number. NOTE: '0' corresponds to label 0, '1' corresponds \n",
    "# to label 1, etc.\n",
    "numberSet = np.array([[np.array(Image.open(f'{number_folder}/{n}')), ord(os.path.splitext(n)[0]) - 48]\n",
    "                      for n in numbers[:]])\n",
    "print(\"Loaded {:} images from folder:\\n{}\".format(numberSet.shape[0], number_folder))\n",
    "\n",
    "# Open the images for letters and label each letter. NOTE: A corresponds to label 10, B to label 11, etc.\n",
    "letterSet = np.array([[np.array(Image.open(f'{letter_folder}/{l}')), ord(os.path.splitext(l)[0]) - 55]\n",
    "                      for l in letters[:]])\n",
    "print(\"Loaded {:} images from folder:\\n{}\".format(letterSet.shape[0], letter_folder))\n",
    "\n",
    "# Concatenate the two data sets to form the X-axis (i.e. character set). Default axis is 0\n",
    "charSet = np.concatenate((numberSet, letterSet))\n",
    "\n",
    "# Generate X and Y axis\n",
    "X_charset_orig = np.array([char[0] for char in charSet[:]])\n",
    "Y_charset_orig = np.array([[char[1]] for char in charSet]).T\n",
    "\n",
    "# Normalize the X dataset by dividing by 255\n",
    "X_charset = X_charset_orig/255.\n",
    "\n",
    "# Generate one hot encoding for Y character set\n",
    "Y_charset = convert_to_one_hot(Y_charset_orig, NUMBER_OF_LABELS).T\n",
    "\n",
    "print(\"Total examples: {:d}\\nTraining examples: {:d}\\nTest examples: {:d}\".\n",
    "     format(X_charset.shape[0],\n",
    "           math.ceil(X_charset.shape[0] * (1-VALIDATION_SPLIT)),             # rounding up\n",
    "           math.floor(X_charset.shape[0] * VALIDATION_SPLIT)))               # rounding down\n",
    "print(\"X shape:\" + str(X_charset.shape))\n",
    "print(\"Y shape:\" + str(Y_charset.shape))\n",
    "\n",
    "# Train CNN\n",
    "# Model definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
